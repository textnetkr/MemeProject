{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba869350",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14ca76d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import swifter\n",
    "from pshmodule.utils import filemanager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be84208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extension : .pickle\n",
      "Loaded 10317 records from /Volumes/GoogleDrive/내 드라이브/MemeProject/data/temp_for_doc2vec.pickle\n"
     ]
    }
   ],
   "source": [
    "df = fm.load(config.origin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16da2c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나 중간고사 반에서 1등했어</td>\n",
       "      <td>[나, 중간고사, 반]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>중간고사 점수 내가 반에서 제일 잘 받음</td>\n",
       "      <td>[중간고사, 점수, 내, 반, 제일, 받음]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>나 반에서 중간 성적 제일 좋아</td>\n",
       "      <td>[나, 반, 중간, 성적, 제일, 좋아]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>우리 반에서 내가 시험 제일 잘 봤다</td>\n",
       "      <td>[우리, 반, 내, 시험, 제일, 봤다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>중간고사 반 1등 먹음</td>\n",
       "      <td>[중간고사, 반, 먹음]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  content                       pos\n",
       "0         나 중간고사 반에서 1등했어              [나, 중간고사, 반]\n",
       "1  중간고사 점수 내가 반에서 제일 잘 받음  [중간고사, 점수, 내, 반, 제일, 받음]\n",
       "2       나 반에서 중간 성적 제일 좋아    [나, 반, 중간, 성적, 제일, 좋아]\n",
       "3    우리 반에서 내가 시험 제일 잘 봤다    [우리, 반, 내, 시험, 제일, 봤다]\n",
       "4            중간고사 반 1등 먹음             [중간고사, 반, 먹음]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95f46cc",
   "metadata": {},
   "source": [
    "### pos concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81606651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713fba1b63844aa68e3323f3ec23037f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/10317 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['pos_str'] = df.pos.swifter.apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c7e732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>나 중간고사 반에서 1등했어</td>\n",
       "      <td>[나, 중간고사, 반]</td>\n",
       "      <td>나 중간고사 반</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>중간고사 점수 내가 반에서 제일 잘 받음</td>\n",
       "      <td>[중간고사, 점수, 내, 반, 제일, 받음]</td>\n",
       "      <td>중간고사 점수 내 반 제일 받음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>나 반에서 중간 성적 제일 좋아</td>\n",
       "      <td>[나, 반, 중간, 성적, 제일, 좋아]</td>\n",
       "      <td>나 반 중간 성적 제일 좋아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>우리 반에서 내가 시험 제일 잘 봤다</td>\n",
       "      <td>[우리, 반, 내, 시험, 제일, 봤다]</td>\n",
       "      <td>우리 반 내 시험 제일 봤다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>중간고사 반 1등 먹음</td>\n",
       "      <td>[중간고사, 반, 먹음]</td>\n",
       "      <td>중간고사 반 먹음</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  content                       pos            pos_str\n",
       "0         나 중간고사 반에서 1등했어              [나, 중간고사, 반]           나 중간고사 반\n",
       "1  중간고사 점수 내가 반에서 제일 잘 받음  [중간고사, 점수, 내, 반, 제일, 받음]  중간고사 점수 내 반 제일 받음\n",
       "2       나 반에서 중간 성적 제일 좋아    [나, 반, 중간, 성적, 제일, 좋아]    나 반 중간 성적 제일 좋아\n",
       "3    우리 반에서 내가 시험 제일 잘 봤다    [우리, 반, 내, 시험, 제일, 봤다]    우리 반 내 시험 제일 봤다\n",
       "4            중간고사 반 1등 먹음             [중간고사, 반, 먹음]          중간고사 반 먹음"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4978e88",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14161ce",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f663bc02",
   "metadata": {},
   "source": [
    "### user defined symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6877505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63349750",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_defined_symbols = [\n",
    "    \"<pad>\",\n",
    "    \"<unk>\",\n",
    "    \"<cls>\",\n",
    "    \"<sep>\",\n",
    "    \"<mask>\",\n",
    "    \"<bos>\",\n",
    "    \"<eos>\",\n",
    "    \"<tsep>\",\n",
    "    \"<name>\",\n",
    "    \"<url>\",\n",
    "    \"<file>\",\n",
    "    \"<image>\",\n",
    "    \"<video>\",\n",
    "    \"<location>\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f5c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_defined_symbols += [f\"<user{i}>\" for i in range(10)]\n",
    "user_defined_symbols += [f\"<unk{i}>\" for i in range(10)]\n",
    "unused_token_num = 100\n",
    "unused_list = [f\"<unused{i}>\" for i in range(unused_token_num)]\n",
    "whole_user_defined_symbols = user_defined_symbols + unused_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ca212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>',\n",
      " '<unk>',\n",
      " '<cls>',\n",
      " '<sep>',\n",
      " '<mask>',\n",
      " '<bos>',\n",
      " '<eos>',\n",
      " '<tsep>',\n",
      " '<name>',\n",
      " '<url>',\n",
      " '<file>',\n",
      " '<image>',\n",
      " '<video>',\n",
      " '<location>',\n",
      " '<user0>',\n",
      " '<user1>',\n",
      " '<user2>',\n",
      " '<user3>',\n",
      " '<user4>',\n",
      " '<user5>',\n",
      " '<user6>',\n",
      " '<user7>',\n",
      " '<user8>',\n",
      " '<user9>',\n",
      " '<unk0>',\n",
      " '<unk1>',\n",
      " '<unk2>',\n",
      " '<unk3>',\n",
      " '<unk4>',\n",
      " '<unk5>',\n",
      " '<unk6>',\n",
      " '<unk7>',\n",
      " '<unk8>',\n",
      " '<unk9>']\n"
     ]
    }
   ],
   "source": [
    "pprint(user_defined_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce49c463",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873eec0f",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95e57768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7601baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c281761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer : <tokenizers.Tokenizer object at 0x107008800>\n"
     ]
    }
   ],
   "source": [
    "print(f\"tokenizer : {tokenizer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52be052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import normalizers\n",
    "from tokenizers.normalizers import NFKC, BertNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "964cd915",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = NFKC()\n",
    "n2 = BertNormalizer(\n",
    "    clean_text=False,\n",
    "    handle_chinese_chars=False,\n",
    "    strip_accents=False,\n",
    "    lowercase=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81186265",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.normalizer = normalizers.Sequence([n1, n2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "839b1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import pre_tokenizers\n",
    "from tokenizers.pre_tokenizers import Metaspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c569dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.Sequence(\n",
    "    [Metaspace(replacement=\"_\", add_prefix_space=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae90caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21e21202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen():\n",
    "    for row in df.pos_str:\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6c7a25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = BpeTrainer(\n",
    "    vocab_size=config.vocab_size,\n",
    "    special_tokens=whole_user_defined_symbols,\n",
    ")\n",
    "tokenizer.train_from_iterator(gen(), trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26597f",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfe49ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer.encode(\"본 고안은 이러한 특성을 이용해 사용한다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2103036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1737, 5545, 951, 1346, 494, 1276, 3100, 748, 952, 1997, 1282, 2161, 3529, 1]\n"
     ]
    }
   ],
   "source": [
    "print(output.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23b8c5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_본 _고안 은 _이 러 한 _특 성 을 _이용 해 _사용 한다'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e11ea590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "872de5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'본 고안은 이러한 특성을 이용해 사용한다'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decoder = decoders.BPEDecoder(suffix=\"_\")\n",
    "tokenizer.decode(output.ids).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a6072",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f010c2",
   "metadata": {},
   "source": [
    "### convert transformers tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91b924c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a376f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_tokenizer = GPT2TokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cef79889",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_tokenizer.pad_token = \"<pad>\"\n",
    "fast_tokenizer.unk_token = \"<unk>\"\n",
    "fast_tokenizer.cls_token = \"<cls>\"\n",
    "fast_tokenizer.sep_token = \"<sep>\"\n",
    "fast_tokenizer.mask_token = \"<mask>\"\n",
    "fast_tokenizer.bos_token = \"<bos>\"\n",
    "fast_tokenizer.eos_token = \"<eos>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5579da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens_dict = {\"additional_special_tokens\": user_defined_symbols}\n",
    "fast_tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e7acc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = fast_tokenizer.encode(\"<user1>'테스트용'으로 \\\"잘\\\" 되는지 보고 있다<sep>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5de1e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 134, 1, 1199, 1823, 924, 1, 3122, 134, 1, 973, 1, 4432, 1026, 1536, 2520, 3]\n",
      "<user1> <unk>테스트용<unk>으로 <unk>잘<unk> 되는지 보고 있다<sep>\n"
     ]
    }
   ],
   "source": [
    "print(e)\n",
    "print(fast_tokenizer.decode(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c66716f",
   "metadata": {},
   "source": [
    "### remove cls sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79a453a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.processors import TemplateProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a7d798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"<cls> $A <sep>\",\n",
    "    pair=\"<cls> $A <sep> $B:1 <sep>:1\",\n",
    "    special_tokens=[(t, i) for i, t in enumerate(user_defined_symbols)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc76e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = fast_tokenizer.encode(\"<user1>'테스트용'으로 \\\"잘\\\" 되는지 보고 있다<sep>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c0c1ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 134, 1, 1199, 1823, 924, 1, 3122, 134, 1, 973, 1, 4432, 1026, 1536, 2520, 3]\n",
      "<user1> <unk>테스트용<unk>으로 <unk>잘<unk> 되는지 보고 있다<sep>\n"
     ]
    }
   ],
   "source": [
    "print(e)\n",
    "print(fast_tokenizer.decode(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad774b",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8b499ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Volumes/GoogleDrive/내 드라이브/MemeProject/model/tokenizer/tokenizer_config.json',\n",
       " '/Volumes/GoogleDrive/내 드라이브/MemeProject/model/tokenizer/special_tokens_map.json',\n",
       " '/Volumes/GoogleDrive/내 드라이브/MemeProject/model/tokenizer/vocab.json',\n",
       " '/Volumes/GoogleDrive/내 드라이브/MemeProject/model/tokenizer/merges.txt',\n",
       " '/Volumes/GoogleDrive/내 드라이브/MemeProject/model/tokenizer/added_tokens.json',\n",
       " '/Volumes/GoogleDrive/내 드라이브/MemeProject/model/tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer.save_pretrained(config.save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537752c",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ce4810",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01ed96c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = AutoTokenizer.from_pretrained(config.save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd385a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1737, 5545, 951, 1346, 494, 1276, 3100, 748, 952, 1997, 1282, 2161, 3529, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      " 본 고안은 이러한 특성을 이용해 사용한다<unk>\n"
     ]
    }
   ],
   "source": [
    "e = t(\"본 고안은 이러한 특성을 이용해 사용한다.\")\n",
    "print(e)\n",
    "print(t.decode(e['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3364c6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
