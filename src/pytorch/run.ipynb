{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOaVyoJAU0rTVHFsskbeHZ5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["# Install"],"metadata":{"id":"FN-Jm9IgyynN"}},{"cell_type":"code","source":["!pip3 install hydra-core"],"metadata":{"id":"g376Z7kty0g5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install transformers"],"metadata":{"id":"cc96tadMzKCR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install datasets"],"metadata":{"id":"BZ8RWnMHrtVA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install pshmodule"],"metadata":{"id":"yzC54sGWPm3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install wandb"],"metadata":{"id":"ElwnbM7TWVCJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"qqomZDQhz488","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674555843911,"user_tz":-540,"elapsed":17751,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"72f6c0b2-7975-40e1-9aca-07099ed96d9b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# GPU Check"],"metadata":{"id":"Fiap6RttXJza"}},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXqlHhTzXz49","executionInfo":{"status":"ok","timestamp":1674555850017,"user_tz":-540,"elapsed":1550,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"93c8d793-11df-40f5-d54e-8c3d08f98c5c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Jan 24 10:24:09 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    54W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbRds2i6X5Hl","executionInfo":{"status":"ok","timestamp":1674555850018,"user_tz":-540,"elapsed":11,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"a740cf5b-b106-4922-e584-069dbe49abd5"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 89.6 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"markdown","source":["# Run"],"metadata":{"id":"1D-Ls5bAXRVN"}},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/MemeProject/src/pytorch/')\n","\n","!python3 train.py"],"metadata":{"id":"ACD6i5ZdXJGa","executionInfo":{"status":"ok","timestamp":1674557323324,"user_tz":-540,"elapsed":7780,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"94225c57-b286-4708-81ed-852266d0aee0"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-24 10:48:36.977567: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","train.py:17: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"./\", config_name=\"config\")\n","/usr/local/lib/python3.8/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","100% 2/2 [00:00<00:00, 811.43it/s]\n","#0:   0% 0/15 [00:00<?, ?ba/s]\n","#0:   0% 0/15 [00:00<?, ?ba/s]\n","\n","\n","#2:   0% 0/15 [00:00<?, ?ba/s]\u001b[A\u001b[AError executing job with overrides: []\n","multiprocess.pool.RemoteTraceback: \n","\"\"\"\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/multiprocess/pool.py\", line 125, in worker\n","    result = (True, func(*args, **kwds))\n","  File \"/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py\", line 562, in wrapper\n","    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py\", line 529, in wrapper\n","    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/datasets/fingerprint.py\", line 480, in wrapper\n","    out = func(self, *args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py\", line 3247, in _map_single\n","    batch = apply_function_on_filtered_inputs(\n","  File \"/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py\", line 3123, in apply_function_on_filtered_inputs\n","    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n","  File \"/content/drive/MyDrive/MemeProject/src/pytorch/dataloader.py\", line 33, in _tokenize_function\n","    for j in c:\n","TypeError: 'int' object is not iterable\n","\"\"\"\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"train.py\", line 23, in main\n","    train_dataset, eval_dataset = load(tokenizer=tokenizer, **cfg.DATASETS)\n","  File \"/content/drive/MyDrive/MemeProject/src/pytorch/dataloader.py\", line 76, in load\n","    data = data.map(\n","  File \"/usr/local/lib/python3.8/dist-packages/datasets/dataset_dict.py\", line 816, in map\n","    {\n","  File \"/usr/local/lib/python3.8/dist-packages/datasets/dataset_dict.py\", line 817, in <dictcomp>\n","    k: dataset.map(\n","  File \"/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py\", line 2939, in map\n","    transformed_shards[index] = async_result.get()\n","  File \"/usr/local/lib/python3.8/dist-packages/multiprocess/pool.py\", line 771, in get\n","    raise self._value\n","  File \"/usr/local/lib/python3.8/dist-packages/multiprocess/pool.py\", line 125, in worker\n","    result = (True, func(*args, **kwds))\n","  File \"/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py\", line 562, in wrapper\n","    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py\", line 529, in wrapper\n","    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/datasets/fingerprint.py\", line 480, in wrapper\n","    out = func(self, *args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py\", line 3247, in _map_single\n","    batch = apply_function_on_filtered_inputs(\n","  File \"/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py\", line 3123, in apply_function_on_filtered_inputs\n","    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n","  File \"/content/drive/MyDrive/MemeProject/src/pytorch/dataloader.py\", line 33, in _tokenize_function\n","    for j in c:\n","TypeError: 'int' object is not iterable\n","\n","Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"4jT7p25KoLli"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3VZtNtLchrEr"},"execution_count":null,"outputs":[]}]}