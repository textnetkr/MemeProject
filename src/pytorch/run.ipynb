{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOvFbdotFTaII00kxHK49Ja"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Install"],"metadata":{"id":"FN-Jm9IgyynN"}},{"cell_type":"code","source":["!pip3 install hydra-core"],"metadata":{"id":"g376Z7kty0g5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install transformers"],"metadata":{"id":"cEWPHH3o6CZk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install datasets"],"metadata":{"id":"BZ8RWnMHrtVA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install evaluate"],"metadata":{"id":"ROJqqGRVClsg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install pshmodule"],"metadata":{"id":"yzC54sGWPm3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install wandb"],"metadata":{"id":"ElwnbM7TWVCJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install pandas==1.5.0"],"metadata":{"id":"2uNv3cQJWAML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install pickle5"],"metadata":{"id":"_1fCWbiNWCZk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"qqomZDQhz488","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674784139366,"user_tz":-540,"elapsed":24188,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"417cea66-0c2f-4a9e-ea33-ed5e69342d7f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# GPU Check"],"metadata":{"id":"Fiap6RttXJza"}},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXqlHhTzXz49","executionInfo":{"status":"ok","timestamp":1674712267332,"user_tz":-540,"elapsed":1430,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"ccd41e7c-5645-4876-9995-b0dde59904dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Jan 26 05:51:06 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    49W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbRds2i6X5Hl","executionInfo":{"status":"ok","timestamp":1674712267333,"user_tz":-540,"elapsed":6,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"24aca0c2-8ef5-436b-94ac-23ea339cd863"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 89.6 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"1D-Ls5bAXRVN"}},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/MemeProject/src/pytorch/')\n","\n","!python3 train.py"],"metadata":{"id":"ACD6i5ZdXJGa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Predict"],"metadata":{"id":"PfcKvvMeB78X"}},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/MemeProject/src/pytorch/')\n","\n","!python3 predict.py"],"metadata":{"id":"4jT7p25KoLli","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674784186570,"user_tz":-540,"elapsed":39885,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"0ecf2b41-b8c0-4f2e-8702-a0a62076d5de"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-27 01:49:11.642004: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","predict.py:11: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"./\", config_name=\"config\")\n","/usr/local/lib/python3.8/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","Downloading (…)okenizer_config.json: 100% 288/288 [00:00<00:00, 46.5kB/s]\n","Downloading (…)lve/main/config.json: 100% 504/504 [00:00<00:00, 202kB/s]\n","Downloading (…)solve/main/vocab.txt: 100% 450k/450k [00:00<00:00, 1.05MB/s]\n","Downloading (…)cial_tokens_map.json: 100% 124/124 [00:00<00:00, 48.1kB/s]\n","tokenizer loading done!\n","model loading done!\n","predict : 459\n","extension : .pickle\n","Loaded 181704 records from /content/drive/MyDrive/MemeProject/data/augmentation/origin_ref.pickle\n","u    태민... 빨리 음원 내줬으면 좋겠따아!!\n","Name: 68208, dtype: object\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GBm7M5KyTEA6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3VZtNtLchrEr"},"execution_count":null,"outputs":[]}]}