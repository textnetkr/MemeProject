{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNjHXcTPZF7BOXORwSD9Hl0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Install"],"metadata":{"id":"FN-Jm9IgyynN"}},{"cell_type":"code","source":["!pip3 install transformers\n","!pip3 install datasets\n","!pip3 install evaluate\n","!pip3 install torch"],"metadata":{"id":"cEWPHH3o6CZk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install pshmodule\n","!pip3 install wandb\n","!pip3 install pandas==1.5.0\n","!pip3 install pickle5\n","!pip3 install hydra-core"],"metadata":{"id":"yzC54sGWPm3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"qqomZDQhz488","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675683534301,"user_tz":-540,"elapsed":16243,"user":{"displayName":"ë°•ì„±í™˜","userId":"16608640204304641951"}},"outputId":"10bfc1ad-84d6-448b-a463-f80f20f681ee"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# GPU Check"],"metadata":{"id":"Fiap6RttXJza"}},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXqlHhTzXz49","executionInfo":{"status":"ok","timestamp":1675683543126,"user_tz":-540,"elapsed":1621,"user":{"displayName":"ë°•ì„±í™˜","userId":"16608640204304641951"}},"outputId":"0926efd2-5a92-42fa-94d4-49b31d6c2917"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Feb  6 11:39:02 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    53W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbRds2i6X5Hl","executionInfo":{"status":"ok","timestamp":1675683543126,"user_tz":-540,"elapsed":5,"user":{"displayName":"ë°•ì„±í™˜","userId":"16608640204304641951"}},"outputId":"7ab6a766-2de0-4aef-9b28-86938933f87b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 89.6 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"1D-Ls5bAXRVN"}},{"cell_type":"code","source":["import os\n","os.chdir('drive/MyDrive/MemeProject/src/pytorch/')\n","\n","!python3 train.py"],"metadata":{"id":"ACD6i5ZdXJGa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cacaac49-e269-4bf0-a5d8-ce5d01865a0b","executionInfo":{"status":"ok","timestamp":1675684016101,"user_tz":-540,"elapsed":472978,"user":{"displayName":"ë°•ì„±í™˜","userId":"16608640204304641951"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-06 11:39:04.697948: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","train.py:20: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"./\", config_name=\"config\")\n","/usr/local/lib/python3.8/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","Downloading (â€¦)okenizer_config.json: 100% 288/288 [00:00<00:00, 48.7kB/s]\n","Downloading (â€¦)lve/main/config.json: 100% 504/504 [00:00<00:00, 230kB/s]\n","Downloading (â€¦)solve/main/vocab.txt: 100% 450k/450k [00:00<00:00, 3.10MB/s]\n","Downloading (â€¦)cial_tokens_map.json: 100% 124/124 [00:00<00:00, 55.7kB/s]\n","Downloading (â€¦)\"pytorch_model.bin\";: 100% 511M/511M [00:02<00:00, 212MB/s]\n","Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-8f5c673f8e2f14ad/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n","Downloading data files: 100% 1/1 [00:00<00:00, 3432.33it/s]\n","Extracting data files: 100% 1/1 [00:00<00:00, 191.60it/s]\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-8f5c673f8e2f14ad/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n","100% 2/2 [00:00<00:00, 719.25it/s]\n","#0:   0% 0/29 [00:00<?, ?ba/s]\n","#1:   0% 0/29 [00:00<?, ?ba/s]\u001b[A\n","\n","#2:   0% 0/29 [00:00<?, ?ba/s]\u001b[A\u001b[A\n","\n","\n","#0:  24% 7/29 [00:00<00:00, 67.45ba/s]\n","#1:  24% 7/29 [00:00<00:00, 69.66ba/s]\u001b[A\n","\n","#2:  31% 9/29 [00:00<00:00, 89.17ba/s]\u001b[A\u001b[A\n","\n","\n","#0:  72% 21/29 [00:00<00:00, 108.24ba/s]\n","#1:  72% 21/29 [00:00<00:00, 109.53ba/s]\u001b[A\n","\n","#2:  79% 23/29 [00:00<00:00, 116.47ba/s]\u001b[A\u001b[A\n","\n","\n","#3: 100% 29/29 [00:00<00:00, 125.41ba/s]\n","#0: 100% 29/29 [00:00<00:00, 110.98ba/s]\n","#1: 100% 29/29 [00:00<00:00, 111.86ba/s]\n","#2: 100% 29/29 [00:00<00:00, 117.52ba/s]\n","#0:   0% 0/8 [00:00<?, ?ba/s]\n","#1:   0% 0/8 [00:00<?, ?ba/s]\u001b[A\n","\n","#2:   0% 0/8 [00:00<?, ?ba/s]\u001b[A\u001b[A\n","\n","\n","#0: 100% 8/8 [00:00<00:00, 109.81ba/s]\n","#1: 100% 8/8 [00:00<00:00, 111.63ba/s]\n","#2: 100% 8/8 [00:00<00:00, 113.06ba/s]\n","#3: 100% 8/8 [00:00<00:00, 114.60ba/s]\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/MemeProject/src/pytorch/outputs/2023-02-06/11-39-12/wandb/run-20230206_113937-bdp9emyz\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbatch64_epoch5_class153_lr1e-4_noweights\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/textnet/MemeProject\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/textnet/MemeProject/runs/bdp9emyz\u001b[0m\n","Downloading builder script: 100% 6.77k/6.77k [00:00<00:00, 6.53MB/s]\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 7320\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 575\n","  Number of trainable parameters = 127894425\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 4.1884, 'learning_rate': 8.260869565217392e-05, 'epoch': 0.87}\n"," 17% 100/575 [01:07<05:03,  1.56it/s]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-100\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-100/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-100/pytorch_model.bin\n"," 20% 115/575 [01:19<04:08,  1.85it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 64\n","\n","  0% 0/29 [00:00<?, ?it/s]\u001b[A\n","  7% 2/29 [00:00<00:02,  9.04it/s]\u001b[A\n"," 10% 3/29 [00:00<00:04,  6.37it/s]\u001b[A\n"," 14% 4/29 [00:00<00:04,  5.54it/s]\u001b[A\n"," 17% 5/29 [00:00<00:04,  5.16it/s]\u001b[A\n"," 21% 6/29 [00:01<00:04,  4.94it/s]\u001b[A\n"," 24% 7/29 [00:01<00:04,  4.81it/s]\u001b[A\n"," 28% 8/29 [00:01<00:04,  4.74it/s]\u001b[A\n"," 31% 9/29 [00:01<00:04,  4.63it/s]\u001b[A\n"," 34% 10/29 [00:01<00:04,  4.60it/s]\u001b[A\n"," 38% 11/29 [00:02<00:03,  4.58it/s]\u001b[A\n"," 41% 12/29 [00:02<00:03,  4.57it/s]\u001b[A\n"," 45% 13/29 [00:02<00:03,  4.55it/s]\u001b[A\n"," 48% 14/29 [00:02<00:03,  4.54it/s]\u001b[A\n"," 52% 15/29 [00:03<00:03,  4.52it/s]\u001b[A\n"," 55% 16/29 [00:03<00:02,  4.51it/s]\u001b[A\n"," 59% 17/29 [00:03<00:02,  4.50it/s]\u001b[A\n"," 62% 18/29 [00:03<00:02,  4.48it/s]\u001b[A\n"," 66% 19/29 [00:03<00:02,  4.50it/s]\u001b[A\n"," 69% 20/29 [00:04<00:02,  4.46it/s]\u001b[A\n"," 72% 21/29 [00:04<00:01,  4.46it/s]\u001b[A\n"," 76% 22/29 [00:04<00:01,  4.43it/s]\u001b[A\n"," 79% 23/29 [00:04<00:01,  4.41it/s]\u001b[A\n"," 83% 24/29 [00:05<00:01,  4.39it/s]\u001b[A\n"," 86% 25/29 [00:05<00:00,  4.45it/s]\u001b[A\n"," 90% 26/29 [00:05<00:00,  4.46it/s]\u001b[A\n"," 93% 27/29 [00:05<00:00,  4.50it/s]\u001b[A\n"," 97% 28/29 [00:06<00:00,  4.52it/s]\u001b[A\n","100% 29/29 [00:06<00:00,  5.12it/s]\u001b[Apred : [152   9  18 ...  89 107  89]\n","labels : [151  81  72 ... 142  18  28]\n","                                     \n","\u001b[A{'eval_loss': 3.627936601638794, 'eval_f1': 0.047310166489559206, 'eval_runtime': 6.395, 'eval_samples_per_second': 286.163, 'eval_steps_per_second': 4.535, 'epoch': 1.0}\n"," 20% 115/575 [01:26<04:08,  1.85it/s]\n","100% 29/29 [00:06<00:00,  5.12it/s]\u001b[A\n","{'loss': 3.0642, 'learning_rate': 6.521739130434783e-05, 'epoch': 1.74}\n"," 35% 200/575 [02:20<04:00,  1.56it/s]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-200\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-200/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-200/pytorch_model.bin\n"," 40% 230/575 [02:45<03:02,  1.89it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 64\n","\n","  0% 0/29 [00:00<?, ?it/s]\u001b[A\n","  7% 2/29 [00:00<00:02,  9.21it/s]\u001b[A\n"," 10% 3/29 [00:00<00:03,  6.50it/s]\u001b[A\n"," 14% 4/29 [00:00<00:04,  5.64it/s]\u001b[A\n"," 17% 5/29 [00:00<00:04,  5.23it/s]\u001b[A\n"," 21% 6/29 [00:01<00:04,  5.00it/s]\u001b[A\n"," 24% 7/29 [00:01<00:04,  4.87it/s]\u001b[A\n"," 28% 8/29 [00:01<00:04,  4.79it/s]\u001b[A\n"," 31% 9/29 [00:01<00:04,  4.73it/s]\u001b[A\n"," 34% 10/29 [00:01<00:04,  4.69it/s]\u001b[A\n"," 38% 11/29 [00:02<00:03,  4.67it/s]\u001b[A\n"," 41% 12/29 [00:02<00:03,  4.65it/s]\u001b[A\n"," 45% 13/29 [00:02<00:03,  4.64it/s]\u001b[A\n"," 48% 14/29 [00:02<00:03,  4.63it/s]\u001b[A\n"," 52% 15/29 [00:03<00:03,  4.62it/s]\u001b[A\n"," 55% 16/29 [00:03<00:02,  4.55it/s]\u001b[A\n"," 59% 17/29 [00:03<00:02,  4.57it/s]\u001b[A\n"," 62% 18/29 [00:03<00:02,  4.58it/s]\u001b[A\n"," 66% 19/29 [00:03<00:02,  4.59it/s]\u001b[A\n"," 69% 20/29 [00:04<00:01,  4.60it/s]\u001b[A\n"," 72% 21/29 [00:04<00:01,  4.60it/s]\u001b[A\n"," 76% 22/29 [00:04<00:01,  4.60it/s]\u001b[A\n"," 79% 23/29 [00:04<00:01,  4.60it/s]\u001b[A\n"," 83% 24/29 [00:05<00:01,  4.61it/s]\u001b[A\n"," 86% 25/29 [00:05<00:00,  4.61it/s]\u001b[A\n"," 90% 26/29 [00:05<00:00,  4.61it/s]\u001b[A\n"," 93% 27/29 [00:05<00:00,  4.61it/s]\u001b[A\n"," 97% 28/29 [00:05<00:00,  4.61it/s]\u001b[A\n","100% 29/29 [00:06<00:00,  5.23it/s]\u001b[Apred : [152   9  18 ...  89 143 101]\n","labels : [151  81  72 ... 142  18  28]\n","                                     \n","\u001b[A{'eval_loss': 3.034289598464966, 'eval_f1': 0.12373570569914424, 'eval_runtime': 6.2352, 'eval_samples_per_second': 293.496, 'eval_steps_per_second': 4.651, 'epoch': 2.0}\n"," 40% 230/575 [02:51<03:02,  1.89it/s]\n","100% 29/29 [00:06<00:00,  5.23it/s]\u001b[A\n","{'loss': 2.2257, 'learning_rate': 4.782608695652174e-05, 'epoch': 2.61}\n"," 52% 300/575 [03:36<02:55,  1.56it/s]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-300\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-300/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-300/pytorch_model.bin\n"," 60% 345/575 [04:08<02:01,  1.89it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 64\n","\n","  0% 0/29 [00:00<?, ?it/s]\u001b[A\n","  7% 2/29 [00:00<00:02,  9.24it/s]\u001b[A\n"," 10% 3/29 [00:00<00:03,  6.51it/s]\u001b[A\n"," 14% 4/29 [00:00<00:04,  5.65it/s]\u001b[A\n"," 17% 5/29 [00:00<00:04,  5.23it/s]\u001b[A\n"," 21% 6/29 [00:01<00:04,  5.01it/s]\u001b[A\n"," 24% 7/29 [00:01<00:04,  4.87it/s]\u001b[A\n"," 28% 8/29 [00:01<00:04,  4.79it/s]\u001b[A\n"," 31% 9/29 [00:01<00:04,  4.73it/s]\u001b[A\n"," 34% 10/29 [00:01<00:04,  4.69it/s]\u001b[A\n"," 38% 11/29 [00:02<00:03,  4.66it/s]\u001b[A\n"," 41% 12/29 [00:02<00:03,  4.65it/s]\u001b[A\n"," 45% 13/29 [00:02<00:03,  4.63it/s]\u001b[A\n"," 48% 14/29 [00:02<00:03,  4.62it/s]\u001b[A\n"," 52% 15/29 [00:03<00:03,  4.62it/s]\u001b[A\n"," 55% 16/29 [00:03<00:02,  4.62it/s]\u001b[A\n"," 59% 17/29 [00:03<00:02,  4.62it/s]\u001b[A\n"," 62% 18/29 [00:03<00:02,  4.62it/s]\u001b[A\n"," 66% 19/29 [00:03<00:02,  4.60it/s]\u001b[A\n"," 69% 20/29 [00:04<00:01,  4.60it/s]\u001b[A\n"," 72% 21/29 [00:04<00:01,  4.59it/s]\u001b[A\n"," 76% 22/29 [00:04<00:01,  4.59it/s]\u001b[A\n"," 79% 23/29 [00:04<00:01,  4.60it/s]\u001b[A\n"," 83% 24/29 [00:04<00:01,  4.60it/s]\u001b[A\n"," 86% 25/29 [00:05<00:00,  4.60it/s]\u001b[A\n"," 90% 26/29 [00:05<00:00,  4.60it/s]\u001b[A\n"," 93% 27/29 [00:05<00:00,  4.60it/s]\u001b[A\n"," 97% 28/29 [00:05<00:00,  4.60it/s]\u001b[A\n","100% 29/29 [00:05<00:00,  5.22it/s]\u001b[Apred : [152 116  36 ...  89 127 101]\n","labels : [151  81  72 ... 142  18  28]\n","                                     \n","\u001b[A{'eval_loss': 2.7170262336730957, 'eval_f1': 0.18457707917422203, 'eval_runtime': 6.2299, 'eval_samples_per_second': 293.745, 'eval_steps_per_second': 4.655, 'epoch': 3.0}\n"," 60% 345/575 [04:14<02:01,  1.89it/s]\n","100% 29/29 [00:06<00:00,  5.22it/s]\u001b[A\n","{'loss': 1.6188, 'learning_rate': 3.0434782608695656e-05, 'epoch': 3.48}\n"," 70% 400/575 [04:50<01:52,  1.56it/s]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-400\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-400/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-400/pytorch_model.bin\n"," 80% 460/575 [05:31<01:00,  1.89it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 64\n","\n","  0% 0/29 [00:00<?, ?it/s]\u001b[A\n","  7% 2/29 [00:00<00:02,  9.20it/s]\u001b[A\n"," 10% 3/29 [00:00<00:04,  6.49it/s]\u001b[A\n"," 14% 4/29 [00:00<00:04,  5.61it/s]\u001b[A\n"," 17% 5/29 [00:00<00:04,  5.09it/s]\u001b[A\n"," 21% 6/29 [00:01<00:04,  4.91it/s]\u001b[A\n"," 24% 7/29 [00:01<00:04,  4.80it/s]\u001b[A\n"," 28% 8/29 [00:01<00:04,  4.73it/s]\u001b[A\n"," 31% 9/29 [00:01<00:04,  4.69it/s]\u001b[A\n"," 34% 10/29 [00:01<00:04,  4.65it/s]\u001b[A\n"," 38% 11/29 [00:02<00:03,  4.62it/s]\u001b[A\n"," 41% 12/29 [00:02<00:03,  4.62it/s]\u001b[A\n"," 45% 13/29 [00:02<00:03,  4.61it/s]\u001b[A\n"," 48% 14/29 [00:02<00:03,  4.61it/s]\u001b[A\n"," 52% 15/29 [00:03<00:03,  4.60it/s]\u001b[A\n"," 55% 16/29 [00:03<00:02,  4.61it/s]\u001b[A\n"," 59% 17/29 [00:03<00:02,  4.61it/s]\u001b[A\n"," 62% 18/29 [00:03<00:02,  4.61it/s]\u001b[A\n"," 66% 19/29 [00:03<00:02,  4.61it/s]\u001b[A\n"," 69% 20/29 [00:04<00:01,  4.61it/s]\u001b[A\n"," 72% 21/29 [00:04<00:01,  4.61it/s]\u001b[A\n"," 76% 22/29 [00:04<00:01,  4.60it/s]\u001b[A\n"," 79% 23/29 [00:04<00:01,  4.60it/s]\u001b[A\n"," 83% 24/29 [00:05<00:01,  4.60it/s]\u001b[A\n"," 86% 25/29 [00:05<00:00,  4.61it/s]\u001b[A\n"," 90% 26/29 [00:05<00:00,  4.61it/s]\u001b[A\n"," 93% 27/29 [00:05<00:00,  4.60it/s]\u001b[A\n"," 97% 28/29 [00:05<00:00,  4.60it/s]\u001b[A\n","100% 29/29 [00:06<00:00,  5.22it/s]\u001b[Apred : [152  39  96 ... 142 127 101]\n","labels : [151  81  72 ... 142  18  28]\n","                                     \n","\u001b[A{'eval_loss': 2.5524439811706543, 'eval_f1': 0.2334847405712964, 'eval_runtime': 6.2531, 'eval_samples_per_second': 292.653, 'eval_steps_per_second': 4.638, 'epoch': 4.0}\n"," 80% 460/575 [05:38<01:00,  1.89it/s]\n","100% 29/29 [00:06<00:00,  5.22it/s]\u001b[A\n","{'loss': 1.1999, 'learning_rate': 1.3043478260869566e-05, 'epoch': 4.35}\n"," 87% 500/575 [06:03<00:48,  1.56it/s]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-500\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-500/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-500/pytorch_model.bin\n","100% 575/575 [06:54<00:00,  1.90it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 64\n","\n","  0% 0/29 [00:00<?, ?it/s]\u001b[A\n","  7% 2/29 [00:00<00:02,  9.22it/s]\u001b[A\n"," 10% 3/29 [00:00<00:03,  6.50it/s]\u001b[A\n"," 14% 4/29 [00:00<00:04,  5.64it/s]\u001b[A\n"," 17% 5/29 [00:00<00:04,  5.23it/s]\u001b[A\n"," 21% 6/29 [00:01<00:04,  5.01it/s]\u001b[A\n"," 24% 7/29 [00:01<00:04,  4.87it/s]\u001b[A\n"," 28% 8/29 [00:01<00:04,  4.78it/s]\u001b[A\n"," 31% 9/29 [00:01<00:04,  4.72it/s]\u001b[A\n"," 34% 10/29 [00:01<00:04,  4.69it/s]\u001b[A\n"," 38% 11/29 [00:02<00:03,  4.66it/s]\u001b[A\n"," 41% 12/29 [00:02<00:03,  4.64it/s]\u001b[A\n"," 45% 13/29 [00:02<00:03,  4.63it/s]\u001b[A\n"," 48% 14/29 [00:02<00:03,  4.62it/s]\u001b[A\n"," 52% 15/29 [00:03<00:03,  4.62it/s]\u001b[A\n"," 55% 16/29 [00:03<00:02,  4.62it/s]\u001b[A\n"," 59% 17/29 [00:03<00:02,  4.61it/s]\u001b[A\n"," 62% 18/29 [00:03<00:02,  4.61it/s]\u001b[A\n"," 66% 19/29 [00:03<00:02,  4.59it/s]\u001b[A\n"," 69% 20/29 [00:04<00:01,  4.59it/s]\u001b[A\n"," 72% 21/29 [00:04<00:01,  4.60it/s]\u001b[A\n"," 76% 22/29 [00:04<00:01,  4.60it/s]\u001b[A\n"," 79% 23/29 [00:04<00:01,  4.60it/s]\u001b[A\n"," 83% 24/29 [00:04<00:01,  4.60it/s]\u001b[A\n"," 86% 25/29 [00:05<00:00,  4.60it/s]\u001b[A\n"," 90% 26/29 [00:05<00:00,  4.59it/s]\u001b[A\n"," 93% 27/29 [00:05<00:00,  4.59it/s]\u001b[A\n"," 97% 28/29 [00:05<00:00,  4.59it/s]\u001b[A\n","100% 29/29 [00:06<00:00,  5.21it/s]\u001b[Apred : [152 110  96 ... 142 127 101]\n","labels : [151  81  72 ... 142  18  28]\n","                                     \n","\u001b[A{'eval_loss': 2.511073112487793, 'eval_f1': 0.25333297293733975, 'eval_runtime': 6.2366, 'eval_samples_per_second': 293.43, 'eval_steps_per_second': 4.65, 'epoch': 5.0}\n","100% 575/575 [07:01<00:00,  1.90it/s]\n","100% 29/29 [00:06<00:00,  5.21it/s]\u001b[A\n","                                   \u001b[A\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 421.0333, 'train_samples_per_second': 86.929, 'train_steps_per_second': 1.366, 'train_loss': 2.2704753842561143, 'epoch': 5.0}\n","100% 575/575 [07:01<00:00,  1.37it/s]\n","Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/models\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/models/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/models/pytorch_model.bin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                        eval/f1 â–â–„â–†â–‡â–ˆ\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss â–ˆâ–„â–‚â–â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime â–ˆâ–â–â–‚â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second â–â–ˆâ–ˆâ–‡â–ˆ\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second â–â–ˆâ–ˆâ–‡â–ˆ\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch â–â–â–‚â–ƒâ–„â–…â–…â–†â–‡â–ˆâ–ˆ\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step â–â–â–‚â–ƒâ–„â–…â–…â–†â–‡â–ˆâ–ˆ\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate â–ˆâ–†â–…â–ƒâ–\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss â–ˆâ–…â–ƒâ–‚â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime â–\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second â–\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                        eval/f1 0.25333\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 2.51107\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 6.2366\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 293.43\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 4.65\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 5.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 575\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 1e-05\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 1.1999\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 4821460244582400.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 2.27048\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 421.0333\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 86.929\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 1.366\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mbatch64_epoch5_class153_lr1e-4_noweights\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/textnet/MemeProject/runs/bdp9emyz\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230206_113937-bdp9emyz/logs\u001b[0m\n"]}]},{"cell_type":"markdown","source":["# Predict"],"metadata":{"id":"PfcKvvMeB78X"}},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/MemeProject/src/pytorch/')\n","\n","!python3 predict.py"],"metadata":{"id":"4jT7p25KoLli"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GBm7M5KyTEA6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3VZtNtLchrEr"},"execution_count":null,"outputs":[]}]}