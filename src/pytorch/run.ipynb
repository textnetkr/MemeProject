{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":["PfcKvvMeB78X"],"authorship_tag":"ABX9TyM9z7VocpgVs0+ocnIysAX7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Install"],"metadata":{"id":"FN-Jm9IgyynN"}},{"cell_type":"code","source":["!pip3 install transformers\n","!pip3 install datasets\n","!pip install evaluate"],"metadata":{"id":"cEWPHH3o6CZk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install pshmodule\n","!pip3 install wandb\n","!pip3 install pandas==1.5.0\n","!pip3 install pickle5\n","!pip3 install hydra-core"],"metadata":{"id":"yzC54sGWPm3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"qqomZDQhz488","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675066071794,"user_tz":-540,"elapsed":22853,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"edfe4495-e4a8-4f16-a7c7-544338f07e72"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# GPU Check"],"metadata":{"id":"Fiap6RttXJza"}},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXqlHhTzXz49","executionInfo":{"status":"ok","timestamp":1675066122104,"user_tz":-540,"elapsed":1224,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"1d091aec-47f6-4170-9bb9-4256e0390b4c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Jan 30 08:08:41 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   30C    P0    50W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbRds2i6X5Hl","executionInfo":{"status":"ok","timestamp":1675066122105,"user_tz":-540,"elapsed":13,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"ae0fac9e-cf57-40cf-d4dd-3b7da379e644"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 89.6 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"1D-Ls5bAXRVN"}},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/MemeProject/src/pytorch/')\n","\n","!python3 train.py"],"metadata":{"id":"ACD6i5ZdXJGa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675067941612,"user_tz":-540,"elapsed":1605547,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"af6b3a99-3f09-44aa-cf82-0e87cade3dc5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-30 08:12:17.410783: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","train.py:15: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"./\", config_name=\"config\")\n","/usr/local/lib/python3.8/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","100% 2/2 [00:00<00:00, 689.74it/s]\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpsh_pat\u001b[0m (\u001b[33mtextnet\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/MemeProject/src/pytorch/outputs/2023-01-30/08-12-22/wandb/run-20230130_081225-xf2bfkzj\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbatch128_epoch10_class154\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/textnet/MemeProject\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/textnet/MemeProject/runs/xf2bfkzj\u001b[0m\n","Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 7320\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1160\n","  Number of trainable parameters = 127895194\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","  5% 58/1160 [01:11<17:20,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.70it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.36it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.36it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [153 151 151 ... 151 151 151]\n","labels : [152  81  72 ... 143  18  28]\n","                                     \n","\u001b[A{'eval_loss': 4.884948253631592, 'eval_f1': 0.010192227935101756, 'eval_runtime': 6.1193, 'eval_samples_per_second': 299.056, 'eval_steps_per_second': 2.451, 'epoch': 1.0}\n","  5% 58/1160 [01:17<17:20,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n","{'loss': 4.8893, 'learning_rate': 9.13793103448276e-06, 'epoch': 1.72}\n","  9% 100/1160 [02:09<21:49,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-100\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-100/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-100/pytorch_model.bin\n"," 10% 116/1160 [02:34<16:47,  1.04it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.55it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.48it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.42it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.38it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.36it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.36it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.35it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[Apred : [152 152 151 ... 152 151 151]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.736230373382568, 'eval_f1': 0.012047310724245256, 'eval_runtime': 6.1219, 'eval_samples_per_second': 298.925, 'eval_steps_per_second': 2.45, 'epoch': 2.0}\n"," 10% 116/1160 [02:40<16:47,  1.04it/s]\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[A\n"," 15% 174/1160 [03:51<15:32,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.68it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.31it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.87it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.66it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.55it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.48it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.36it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[Apred : [153 151 151 ... 152 151 151]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.562280654907227, 'eval_f1': 0.012440419840333618, 'eval_runtime': 6.1155, 'eval_samples_per_second': 299.238, 'eval_steps_per_second': 2.453, 'epoch': 3.0}\n"," 15% 174/1160 [03:57<15:32,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[A\n","{'loss': 4.5594, 'learning_rate': 8.275862068965518e-06, 'epoch': 3.45}\n"," 17% 200/1160 [04:29<19:47,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-200\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-200/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-200/pytorch_model.bin\n"," 20% 232/1160 [05:11<14:38,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.68it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [153 151 151 ... 152 151 151]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.387185573577881, 'eval_f1': 0.02030616757444594, 'eval_runtime': 6.0938, 'eval_samples_per_second': 300.306, 'eval_steps_per_second': 2.462, 'epoch': 4.0}\n"," 20% 232/1160 [05:17<14:38,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n"," 25% 290/1160 [06:28<13:43,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [153   9 108 ... 152 108 152]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.220170021057129, 'eval_f1': 0.03154839247865247, 'eval_runtime': 6.0977, 'eval_samples_per_second': 300.111, 'eval_steps_per_second': 2.46, 'epoch': 5.0}\n"," 25% 290/1160 [06:34<13:43,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n","{'loss': 4.2182, 'learning_rate': 7.413793103448277e-06, 'epoch': 5.17}\n"," 26% 300/1160 [06:47<18:40,  1.30s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-300\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-300/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-300/pytorch_model.bin\n"," 30% 348/1160 [07:49<12:47,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [153   9 108 ... 152 108  89]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.0829033851623535, 'eval_f1': 0.03782407572651338, 'eval_runtime': 6.1004, 'eval_samples_per_second': 299.978, 'eval_steps_per_second': 2.459, 'epoch': 6.0}\n"," 30% 348/1160 [07:55<12:47,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n","{'loss': 3.8939, 'learning_rate': 6.551724137931035e-06, 'epoch': 6.9}\n"," 34% 400/1160 [08:59<15:41,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-400\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-400/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-400/pytorch_model.bin\n"," 35% 406/1160 [09:09<14:27,  1.15s/it]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.68it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.28it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.86it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.66it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.55it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.38it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.36it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [153   9 108 ...  89 108  89]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 3.9670917987823486, 'eval_f1': 0.04710210616158445, 'eval_runtime': 6.116, 'eval_samples_per_second': 299.213, 'eval_steps_per_second': 2.453, 'epoch': 7.0}\n"," 35% 406/1160 [09:16<14:27,  1.15s/it]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n"," 40% 464/1160 [10:26<10:57,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.55it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [153   9 110 ...  89 108  89]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 3.864166736602783, 'eval_f1': 0.055216322403855184, 'eval_runtime': 6.0984, 'eval_samples_per_second': 300.081, 'eval_steps_per_second': 2.46, 'epoch': 8.0}\n"," 40% 464/1160 [10:32<10:57,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n","{'loss': 3.6478, 'learning_rate': 5.689655172413794e-06, 'epoch': 8.62}\n"," 43% 500/1160 [11:17<13:35,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-500\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-500/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-500/pytorch_model.bin\n"," 45% 522/1160 [11:47<10:02,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [153   9  80 ...  89 108  89]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 3.784945011138916, 'eval_f1': 0.06393034241025544, 'eval_runtime': 6.099, 'eval_samples_per_second': 300.049, 'eval_steps_per_second': 2.459, 'epoch': 9.0}\n"," 45% 522/1160 [11:53<10:02,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n"," 50% 580/1160 [13:03<09:07,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.71it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.68it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [153   9  18 ... 143 108  89]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 3.698636293411255, 'eval_f1': 0.07577626531839173, 'eval_runtime': 6.095, 'eval_samples_per_second': 300.246, 'eval_steps_per_second': 2.461, 'epoch': 10.0}\n"," 50% 580/1160 [13:10<09:07,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n","{'loss': 3.4333, 'learning_rate': 4.8275862068965525e-06, 'epoch': 10.34}\n"," 52% 600/1160 [13:34<11:32,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-600\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-600/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-600/pytorch_model.bin\n"," 55% 638/1160 [14:24<08:13,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.73it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.39it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [153   9  96 ... 143 110  89]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 3.6532959938049316, 'eval_f1': 0.08585363685391569, 'eval_runtime': 6.0921, 'eval_samples_per_second': 300.391, 'eval_steps_per_second': 2.462, 'epoch': 11.0}\n"," 55% 638/1160 [14:30<08:13,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n"," 60% 696/1160 [15:41<07:18,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.89it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.68it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.57it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.39it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.37it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.99it/s]\u001b[Apred : [153   9  96 ... 143 108  89]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 3.5924885272979736, 'eval_f1': 0.10248109241257464, 'eval_runtime': 6.0843, 'eval_samples_per_second': 300.773, 'eval_steps_per_second': 2.465, 'epoch': 12.0}\n"," 60% 696/1160 [15:47<07:18,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.99it/s]\u001b[A\n","{'loss': 3.2732, 'learning_rate': 3.96551724137931e-06, 'epoch': 12.07}\n"," 60% 700/1160 [15:52<13:43,  1.79s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-700\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-700/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-700/pytorch_model.bin\n"," 65% 754/1160 [17:01<06:24,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.73it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.89it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.68it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.39it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.37it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.99it/s]\u001b[Apred : [153   9  96 ... 143 108  89]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 3.554628372192383, 'eval_f1': 0.1061994613405562, 'eval_runtime': 6.0831, 'eval_samples_per_second': 300.834, 'eval_steps_per_second': 2.466, 'epoch': 13.0}\n"," 65% 754/1160 [17:07<06:24,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.99it/s]\u001b[A\n","{'loss': 3.1517, 'learning_rate': 3.103448275862069e-06, 'epoch': 13.79}\n"," 69% 800/1160 [18:04<07:24,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-800\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-800/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-800/pytorch_model.bin\n"," 70% 812/1160 [18:21<05:37,  1.03it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.70it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.37it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [153   9  96 ... 143 110 119]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 3.510164499282837, 'eval_f1': 0.10382248014631351, 'eval_runtime': 6.0974, 'eval_samples_per_second': 300.129, 'eval_steps_per_second': 2.46, 'epoch': 14.0}\n"," 70% 812/1160 [18:27<05:37,  1.03it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n"," 75% 870/1160 [19:38<04:33,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.31it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.39it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.37it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.99it/s]\u001b[Apred : [153   9  96 ... 143 110 119]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 3.4929778575897217, 'eval_f1': 0.11400305262767418, 'eval_runtime': 6.0927, 'eval_samples_per_second': 300.357, 'eval_steps_per_second': 2.462, 'epoch': 15.0}\n"," 75% 870/1160 [19:44<04:33,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.99it/s]\u001b[A\n","{'loss': 3.0593, 'learning_rate': 2.241379310344828e-06, 'epoch': 15.52}\n"," 78% 900/1160 [20:21<05:21,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-900\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-900/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-900/pytorch_model.bin\n"," 80% 928/1160 [20:58<03:39,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.89it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.68it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [153   9  96 ... 143 110 119]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 3.451444149017334, 'eval_f1': 0.1168347327853186, 'eval_runtime': 6.0977, 'eval_samples_per_second': 300.112, 'eval_steps_per_second': 2.46, 'epoch': 16.0}\n"," 80% 928/1160 [21:04<03:39,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n"," 85% 986/1160 [22:15<02:44,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.73it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.89it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.68it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.48it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.39it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.37it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.99it/s]\u001b[Apred : [153   9  96 ... 143 110 101]\n","labels : [152  81  72 ... 143  18  28]\n","                                      \n","\u001b[A{'eval_loss': 3.430371046066284, 'eval_f1': 0.11752319939740109, 'eval_runtime': 6.0967, 'eval_samples_per_second': 300.164, 'eval_steps_per_second': 2.46, 'epoch': 17.0}\n"," 85% 986/1160 [22:21<02:44,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.99it/s]\u001b[A\n","{'loss': 2.9867, 'learning_rate': 1.3793103448275862e-06, 'epoch': 17.24}\n"," 86% 1000/1160 [22:38<03:20,  1.25s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-1000\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-1000/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-1000/pytorch_model.bin\n"," 90% 1044/1160 [23:35<01:49,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.73it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.89it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.68it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.39it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.37it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.99it/s]\u001b[Apred : [153   9  96 ... 143 110 101]\n","labels : [152  81  72 ... 143  18  28]\n","                                       \n","\u001b[A{'eval_loss': 3.4221456050872803, 'eval_f1': 0.11769907522506308, 'eval_runtime': 6.0904, 'eval_samples_per_second': 300.473, 'eval_steps_per_second': 2.463, 'epoch': 18.0}\n"," 90% 1044/1160 [23:41<01:49,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.99it/s]\u001b[A\n","{'loss': 2.9333, 'learning_rate': 5.172413793103449e-07, 'epoch': 18.97}\n"," 95% 1100/1160 [24:51<01:14,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-1100\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-1100/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-1100/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-100] due to args.save_total_limit\n"," 95% 1102/1160 [24:57<01:56,  2.02s/it]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.89it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.68it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.39it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.37it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.99it/s]\u001b[Apred : [153   9  96 ... 143 110 101]\n","labels : [152  81  72 ... 143  18  28]\n","                                       \n","\u001b[A{'eval_loss': 3.410614013671875, 'eval_f1': 0.11655230016654465, 'eval_runtime': 6.0917, 'eval_samples_per_second': 300.407, 'eval_steps_per_second': 2.462, 'epoch': 19.0}\n"," 95% 1102/1160 [25:03<01:56,  2.02s/it]\n","100% 15/15 [00:05<00:00,  2.99it/s]\u001b[A\n","100% 1160/1160 [26:14<00:00,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.89it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.68it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.39it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.37it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.99it/s]\u001b[Apred : [153   9  96 ... 143 110 101]\n","labels : [152  81  72 ... 143  18  28]\n","                                       \n","\u001b[A{'eval_loss': 3.406060218811035, 'eval_f1': 0.11693472306737049, 'eval_runtime': 6.0856, 'eval_samples_per_second': 300.71, 'eval_steps_per_second': 2.465, 'epoch': 20.0}\n","100% 1160/1160 [26:20<00:00,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.99it/s]\u001b[A\n","                                   \u001b[A\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 1580.5562, 'train_samples_per_second': 92.626, 'train_steps_per_second': 0.734, 'train_loss': 3.6038128293793776, 'epoch': 20.0}\n","100% 1160/1160 [26:20<00:00,  1.36s/it]\n","Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/models\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/models/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/models/pytorch_model.bin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                        eval/f1 ▁▁▁▂▂▃▃▄▄▅▆▇▇▇██████\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▇▆▆▅▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ██▇▃▄▄▇▄▄▃▃▁▁▄▃▄▃▂▃▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▁▁▂▆▅▅▂▅▅▆▆██▅▆▅▆▇▆█\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▁▁▂▆▅▅▂▅▅▆▆██▅▆▅▅▇▆█\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate █▇▇▆▅▅▄▃▂▂▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▇▆▄▄▃▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                        eval/f1 0.11693\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 3.40606\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 6.0856\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 300.71\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 2.465\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 20.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 1160\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 2.9333\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.92860139036672e+16\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 3.60381\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 1580.5562\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 92.626\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.734\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mbatch128_epoch10_class154\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/textnet/MemeProject/runs/xf2bfkzj\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230130_081225-xf2bfkzj/logs\u001b[0m\n"]}]},{"cell_type":"markdown","source":["# Predict"],"metadata":{"id":"PfcKvvMeB78X"}},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/MemeProject/src/pytorch/')\n","\n","!python3 predict.py"],"metadata":{"id":"4jT7p25KoLli","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674784186570,"user_tz":-540,"elapsed":39885,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"0ecf2b41-b8c0-4f2e-8702-a0a62076d5de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-27 01:49:11.642004: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","predict.py:11: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"./\", config_name=\"config\")\n","/usr/local/lib/python3.8/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","Downloading (…)okenizer_config.json: 100% 288/288 [00:00<00:00, 46.5kB/s]\n","Downloading (…)lve/main/config.json: 100% 504/504 [00:00<00:00, 202kB/s]\n","Downloading (…)solve/main/vocab.txt: 100% 450k/450k [00:00<00:00, 1.05MB/s]\n","Downloading (…)cial_tokens_map.json: 100% 124/124 [00:00<00:00, 48.1kB/s]\n","tokenizer loading done!\n","model loading done!\n","predict : 459\n","extension : .pickle\n","Loaded 181704 records from /content/drive/MyDrive/MemeProject/data/augmentation/origin_ref.pickle\n","u    태민... 빨리 음원 내줬으면 좋겠따아!!\n","Name: 68208, dtype: object\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GBm7M5KyTEA6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3VZtNtLchrEr"},"execution_count":null,"outputs":[]}]}