{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMREsJxuBxEwO2TCV8VMhWo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Install"],"metadata":{"id":"FN-Jm9IgyynN"}},{"cell_type":"code","source":["!pip3 install transformers\n","!pip3 install datasets\n","!pip3 install evaluate\n","!pip3 install torch"],"metadata":{"id":"cEWPHH3o6CZk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install pshmodule\n","!pip3 install wandb\n","!pip3 install pandas==1.5.0\n","!pip3 install pickle5\n","!pip3 install hydra-core"],"metadata":{"id":"yzC54sGWPm3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"qqomZDQhz488","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675670238676,"user_tz":-540,"elapsed":34631,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"88a45ceb-3381-45f9-f9c2-39f4a1e3a23a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# GPU Check"],"metadata":{"id":"Fiap6RttXJza"}},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXqlHhTzXz49","executionInfo":{"status":"ok","timestamp":1675670341472,"user_tz":-540,"elapsed":2079,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"5a1f136c-4e8d-47f6-838a-dc765be4b66a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Feb  6 07:58:59 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    46W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbRds2i6X5Hl","executionInfo":{"status":"ok","timestamp":1675670341473,"user_tz":-540,"elapsed":11,"user":{"displayName":"박성환","userId":"16608640204304641951"}},"outputId":"fa6e827e-7cc0-497c-db13-06919070cc45"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 89.6 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"1D-Ls5bAXRVN"}},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/MemeProject/src/pytorch/')\n","\n","!python3 train.py"],"metadata":{"id":"ACD6i5ZdXJGa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"53f6e50e-90c7-44ed-a111-1c9f4a1ad7f7","executionInfo":{"status":"ok","timestamp":1675672215006,"user_tz":-540,"elapsed":1612090,"user":{"displayName":"박성환","userId":"16608640204304641951"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-06 08:03:23.739036: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","train.py:20: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"./\", config_name=\"config\")\n","/usr/local/lib/python3.8/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","100% 2/2 [00:00<00:00, 625.22it/s]\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpsh_pat\u001b[0m (\u001b[33mtextnet\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/MemeProject/src/pytorch/outputs/2023-02-06/08-03-28/wandb/run-20230206_080332-bmv8u3al\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbatch128_epoch20_class153\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/textnet/MemeProject\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/textnet/MemeProject/runs/bmv8u3al\u001b[0m\n","Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 7320\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 128\n","  Total train batch size (w. parallel, distributed & accumulation) = 128\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1160\n","  Number of trainable parameters = 127894425\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","  5% 58/1160 [01:11<17:23,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.67it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.31it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.87it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.48it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [ 56 118 136 ... 136 103 103]\n","labels : [151  81  72 ... 142  18  28]\n","                                     \n","\u001b[A{'eval_loss': 5.0435872077941895, 'eval_f1': 0.0031999742260301832, 'eval_runtime': 6.1163, 'eval_samples_per_second': 299.202, 'eval_steps_per_second': 2.452, 'epoch': 1.0}\n","  5% 58/1160 [01:17<17:23,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n","{'loss': 5.0149, 'learning_rate': 9.13793103448276e-06, 'epoch': 1.72}\n","  9% 100/1160 [02:09<21:51,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-100\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-100/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-100/pytorch_model.bin\n"," 10% 116/1160 [02:32<16:34,  1.05it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.68it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.37it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [ 56 118 136 ... 136 103 103]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 5.045191764831543, 'eval_f1': 0.004553078059123356, 'eval_runtime': 6.0911, 'eval_samples_per_second': 300.438, 'eval_steps_per_second': 2.463, 'epoch': 2.0}\n"," 10% 116/1160 [02:38<16:34,  1.05it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n"," 15% 174/1160 [03:49<15:34,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.71it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.55it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.37it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [ 56 118 136 ... 136 103  96]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 5.039146900177002, 'eval_f1': 0.009340630159547978, 'eval_runtime': 6.0984, 'eval_samples_per_second': 300.078, 'eval_steps_per_second': 2.46, 'epoch': 3.0}\n"," 15% 174/1160 [03:55<15:34,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n","{'loss': 4.9633, 'learning_rate': 8.275862068965518e-06, 'epoch': 3.45}\n"," 17% 200/1160 [04:27<19:52,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-200\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-200/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-200/pytorch_model.bin\n"," 20% 232/1160 [05:10<14:37,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.55it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.48it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.43it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.36it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[Apred : [ 56 118  62 ...  89 103 118]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 5.017824649810791, 'eval_f1': 0.024141921913463007, 'eval_runtime': 6.1132, 'eval_samples_per_second': 299.352, 'eval_steps_per_second': 2.454, 'epoch': 4.0}\n"," 20% 232/1160 [05:17<14:37,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[A\n"," 25% 290/1160 [06:27<13:43,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.68it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.36it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[Apred : [129 118  62 ...  89 103 118]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.99107551574707, 'eval_f1': 0.034705437989226755, 'eval_runtime': 6.1031, 'eval_samples_per_second': 299.847, 'eval_steps_per_second': 2.458, 'epoch': 5.0}\n"," 25% 290/1160 [06:34<13:43,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[A\n","{'loss': 4.8771, 'learning_rate': 7.413793103448277e-06, 'epoch': 5.17}\n"," 26% 300/1160 [06:46<18:42,  1.31s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-300\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-300/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-300/pytorch_model.bin\n"," 30% 348/1160 [07:48<12:48,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.85it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.66it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.54it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.48it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [129 118 115 ...  89  70 118]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.953896522521973, 'eval_f1': 0.0448447416601955, 'eval_runtime': 6.1067, 'eval_samples_per_second': 299.671, 'eval_steps_per_second': 2.456, 'epoch': 6.0}\n"," 30% 348/1160 [07:54<12:48,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n","{'loss': 4.7661, 'learning_rate': 6.551724137931035e-06, 'epoch': 6.9}\n"," 34% 400/1160 [08:59<15:41,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-400\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-400/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-400/pytorch_model.bin\n"," 35% 406/1160 [09:11<15:29,  1.23s/it]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.71it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [129 118  62 ...  89 119  97]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.915600299835205, 'eval_f1': 0.049091235694983644, 'eval_runtime': 6.0981, 'eval_samples_per_second': 300.092, 'eval_steps_per_second': 2.46, 'epoch': 7.0}\n"," 35% 406/1160 [09:17<15:29,  1.23s/it]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n"," 40% 464/1160 [10:28<10:58,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.71it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [149 118 115 ...  89  70  97]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.877016067504883, 'eval_f1': 0.047721962120781405, 'eval_runtime': 6.0975, 'eval_samples_per_second': 300.125, 'eval_steps_per_second': 2.46, 'epoch': 8.0}\n"," 40% 464/1160 [10:34<10:58,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n","{'loss': 4.6435, 'learning_rate': 5.689655172413794e-06, 'epoch': 8.62}\n"," 43% 500/1160 [11:18<13:37,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-500\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-500/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-500/pytorch_model.bin\n"," 45% 522/1160 [11:48<10:07,  1.05it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [149 118 115 ...  89  70  97]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.841195106506348, 'eval_f1': 0.050159650841815916, 'eval_runtime': 6.1012, 'eval_samples_per_second': 299.941, 'eval_steps_per_second': 2.459, 'epoch': 9.0}\n"," 45% 522/1160 [11:54<10:07,  1.05it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n"," 50% 580/1160 [13:05<09:08,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.71it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.87it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.66it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.55it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.48it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.36it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.35it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[Apred : [151 118  62 ...  89  70  55]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.80659294128418, 'eval_f1': 0.0524203168370787, 'eval_runtime': 6.1208, 'eval_samples_per_second': 298.982, 'eval_steps_per_second': 2.451, 'epoch': 10.0}\n"," 50% 580/1160 [13:11<09:08,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[A\n","{'loss': 4.5243, 'learning_rate': 4.8275862068965525e-06, 'epoch': 10.34}\n"," 52% 600/1160 [13:36<11:34,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-600\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-600/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-600/pytorch_model.bin\n"," 55% 638/1160 [14:25<08:13,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.71it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.31it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.87it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.66it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.55it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.48it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.36it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.36it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.35it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[Apred : [151 118  62 ...  89  36  55]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.770406246185303, 'eval_f1': 0.06679095137566077, 'eval_runtime': 6.1224, 'eval_samples_per_second': 298.903, 'eval_steps_per_second': 2.45, 'epoch': 11.0}\n"," 55% 638/1160 [14:32<08:13,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[A\n"," 60% 696/1160 [15:42<07:18,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.36it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [151 118  96 ...  89  36  55]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.739223480224609, 'eval_f1': 0.06864213646342533, 'eval_runtime': 6.1047, 'eval_samples_per_second': 299.77, 'eval_steps_per_second': 2.457, 'epoch': 12.0}\n"," 60% 696/1160 [15:48<07:18,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n","{'loss': 4.4154, 'learning_rate': 3.96551724137931e-06, 'epoch': 12.07}\n"," 60% 700/1160 [15:53<13:47,  1.80s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-700\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-700/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-700/pytorch_model.bin\n"," 65% 754/1160 [17:05<06:24,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.69it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.31it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.87it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.55it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.36it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [151  93  62 ...  89  36  55]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.716215133666992, 'eval_f1': 0.07113157835814275, 'eval_runtime': 6.1076, 'eval_samples_per_second': 299.629, 'eval_steps_per_second': 2.456, 'epoch': 13.0}\n"," 65% 754/1160 [17:11<06:24,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n","{'loss': 4.3184, 'learning_rate': 3.103448275862069e-06, 'epoch': 13.79}\n"," 69% 800/1160 [18:08<07:25,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-800\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-800/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-800/pytorch_model.bin\n"," 70% 812/1160 [18:26<05:37,  1.03it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.71it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.87it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.55it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.48it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [151  93  62 ...  89  36  55]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.693904876708984, 'eval_f1': 0.0725495648846852, 'eval_runtime': 6.1193, 'eval_samples_per_second': 299.054, 'eval_steps_per_second': 2.451, 'epoch': 14.0}\n"," 70% 812/1160 [18:32<05:37,  1.03it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n"," 75% 870/1160 [19:43<04:35,  1.05it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.55it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [151 118  96 ...  89   6 142]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.673444747924805, 'eval_f1': 0.07265781434741247, 'eval_runtime': 6.0967, 'eval_samples_per_second': 300.161, 'eval_steps_per_second': 2.46, 'epoch': 15.0}\n"," 75% 870/1160 [19:49<04:35,  1.05it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n","{'loss': 4.2446, 'learning_rate': 2.241379310344828e-06, 'epoch': 15.52}\n"," 78% 900/1160 [20:26<05:21,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-900\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-900/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-900/pytorch_model.bin\n"," 80% 928/1160 [21:03<03:39,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.72it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.33it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.89it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.68it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [151  93  96 ...  89   6 142]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.658095359802246, 'eval_f1': 0.07434031990017938, 'eval_runtime': 6.0948, 'eval_samples_per_second': 300.256, 'eval_steps_per_second': 2.461, 'epoch': 16.0}\n"," 80% 928/1160 [21:09<03:39,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n"," 85% 986/1160 [22:20<02:44,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.70it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.55it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.48it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.36it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[Apred : [151  93  62 ...  89   6 142]\n","labels : [151  81  72 ... 142  18  28]\n","                                      \n","\u001b[A{'eval_loss': 4.645676612854004, 'eval_f1': 0.07639650763687551, 'eval_runtime': 6.1077, 'eval_samples_per_second': 299.623, 'eval_steps_per_second': 2.456, 'epoch': 17.0}\n"," 85% 986/1160 [22:26<02:44,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[A\n","{'loss': 4.184, 'learning_rate': 1.3793103448275862e-06, 'epoch': 17.24}\n"," 86% 1000/1160 [22:44<03:20,  1.25s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-1000\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-1000/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-1000/pytorch_model.bin\n"," 90% 1044/1160 [23:41<01:49,  1.06it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.70it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.31it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.87it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.54it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.48it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.37it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.36it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.36it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.36it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[Apred : [151  93  96 ...  89   6 142]\n","labels : [151  81  72 ... 142  18  28]\n","                                       \n","\u001b[A{'eval_loss': 4.635817050933838, 'eval_f1': 0.07885702118064156, 'eval_runtime': 6.1248, 'eval_samples_per_second': 298.785, 'eval_steps_per_second': 2.449, 'epoch': 18.0}\n"," 90% 1044/1160 [23:47<01:49,  1.06it/s]\n","100% 15/15 [00:05<00:00,  2.97it/s]\u001b[A\n","{'loss': 4.1495, 'learning_rate': 5.172413793103449e-07, 'epoch': 18.97}\n"," 95% 1100/1160 [24:56<01:14,  1.24s/it]Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-1100\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-1100/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-1100/pytorch_model.bin\n","Deleting older checkpoint [/content/drive/MyDrive/MemeProject/model/pytorch/checkpoints/checkpoint-100] due to args.save_total_limit\n"," 95% 1102/1160 [25:01<01:36,  1.66s/it]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.71it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.28it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.84it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.65it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.54it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.48it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.44it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.41it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.39it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [151  93  96 ...  89   6 142]\n","labels : [151  81  72 ... 142  18  28]\n","                                       \n","\u001b[A{'eval_loss': 4.6304144859313965, 'eval_f1': 0.08224399029393893, 'eval_runtime': 6.1216, 'eval_samples_per_second': 298.944, 'eval_steps_per_second': 2.45, 'epoch': 19.0}\n"," 95% 1102/1160 [25:07<01:36,  1.66s/it]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n","100% 1160/1160 [26:18<00:00,  1.05it/s]***** Running Evaluation *****\n","  Num examples = 1830\n","  Batch size = 128\n","\n","  0% 0/15 [00:00<?, ?it/s]\u001b[A\n"," 13% 2/15 [00:00<00:02,  4.71it/s]\u001b[A\n"," 20% 3/15 [00:00<00:03,  3.32it/s]\u001b[A\n"," 27% 4/15 [00:01<00:03,  2.88it/s]\u001b[A\n"," 33% 5/15 [00:01<00:03,  2.67it/s]\u001b[A\n"," 40% 6/15 [00:02<00:03,  2.56it/s]\u001b[A\n"," 47% 7/15 [00:02<00:03,  2.49it/s]\u001b[A\n"," 53% 8/15 [00:02<00:02,  2.45it/s]\u001b[A\n"," 60% 9/15 [00:03<00:02,  2.42it/s]\u001b[A\n"," 67% 10/15 [00:03<00:02,  2.40it/s]\u001b[A\n"," 73% 11/15 [00:04<00:01,  2.38it/s]\u001b[A\n"," 80% 12/15 [00:04<00:01,  2.37it/s]\u001b[A\n"," 87% 13/15 [00:05<00:00,  2.37it/s]\u001b[A\n"," 93% 14/15 [00:05<00:00,  2.36it/s]\u001b[A\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[Apred : [151  93  96 ...  89   6 142]\n","labels : [151  81  72 ... 142  18  28]\n","                                       \n","\u001b[A{'eval_loss': 4.6293511390686035, 'eval_f1': 0.08163552730539782, 'eval_runtime': 6.0966, 'eval_samples_per_second': 300.166, 'eval_steps_per_second': 2.46, 'epoch': 20.0}\n","100% 1160/1160 [26:24<00:00,  1.05it/s]\n","100% 15/15 [00:05<00:00,  2.98it/s]\u001b[A\n","                                   \u001b[A\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 1584.9616, 'train_samples_per_second': 92.368, 'train_steps_per_second': 0.732, 'train_loss': 4.533040079577216, 'epoch': 20.0}\n","100% 1160/1160 [26:24<00:00,  1.37s/it]\n","Saving model checkpoint to /content/drive/MyDrive/MemeProject/model/pytorch/models\n","Configuration saved in /content/drive/MyDrive/MemeProject/model/pytorch/models/config.json\n","Model weights saved in /content/drive/MyDrive/MemeProject/model/pytorch/models/pytorch_model.bin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                        eval/f1 ▁▁▂▃▄▅▅▅▅▅▇▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ████▇▆▆▅▅▄▃▃▂▂▂▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▆▁▃▆▃▄▂▂▃▇█▄▄▇▂▂▄█▇▂\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▃█▆▃▅▅▇▇▆▂▁▅▅▂▇▇▅▁▂▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▂█▇▄▅▅▇▇▆▂▂▅▅▂▇▇▅▁▂▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate █▇▇▆▅▅▄▃▂▂▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss ██▇▆▅▄▃▂▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                        eval/f1 0.08164\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 4.62935\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 6.0966\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 300.166\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 2.46\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 20.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 1160\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 4.1495\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.92858409783296e+16\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 4.53304\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 1584.9616\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 92.368\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.732\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mbatch128_epoch20_class153\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/textnet/MemeProject/runs/bmv8u3al\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230206_080332-bmv8u3al/logs\u001b[0m\n"]}]},{"cell_type":"markdown","source":["# Predict"],"metadata":{"id":"PfcKvvMeB78X"}},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/MemeProject/src/pytorch/')\n","\n","!python3 predict.py"],"metadata":{"id":"4jT7p25KoLli"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GBm7M5KyTEA6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3VZtNtLchrEr"},"execution_count":null,"outputs":[]}]}