{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":["1D-Ls5bAXRVN"],"authorship_tag":"ABX9TyNseppFXs1hnSt83cFqCP1s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Install"],"metadata":{"id":"FN-Jm9IgyynN"}},{"cell_type":"code","source":["!pip3 install transformers\n","!pip3 install datasets\n","!pip3 install evaluate\n","!pip3 install torch"],"metadata":{"id":"cEWPHH3o6CZk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip3 install pshmodule\n","!pip3 install wandb\n","!pip3 install pandas==1.5.0\n","!pip3 install pickle5\n","!pip3 install hydra-core"],"metadata":{"id":"yzC54sGWPm3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"qqomZDQhz488","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677135926110,"user_tz":-540,"elapsed":30760,"user":{"displayName":"ë°•ì„±í™˜","userId":"16608640204304641951"}},"outputId":"d91234f0-a9fb-41ec-ad2c-7c04ee356a2d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# GPU Check"],"metadata":{"id":"Fiap6RttXJza"}},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXqlHhTzXz49","executionInfo":{"status":"ok","timestamp":1677135927001,"user_tz":-540,"elapsed":896,"user":{"displayName":"ë°•ì„±í™˜","userId":"16608640204304641951"}},"outputId":"816d58d1-e662-42b4-93c6-ad981d890edb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Feb 23 07:05:26 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    51W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbRds2i6X5Hl","executionInfo":{"status":"ok","timestamp":1677135927001,"user_tz":-540,"elapsed":4,"user":{"displayName":"ë°•ì„±í™˜","userId":"16608640204304641951"}},"outputId":"0df21410-409e-422a-fdbf-8d6cc2560ad8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 89.6 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"1D-Ls5bAXRVN"}},{"cell_type":"code","source":["import os\n","os.chdir('drive/MyDrive/MemeProject/src/pytorch/')"],"metadata":{"id":"ACD6i5ZdXJGa","executionInfo":{"status":"ok","timestamp":1677135927621,"user_tz":-540,"elapsed":622,"user":{"displayName":"ë°•ì„±í™˜","userId":"16608640204304641951"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!python3 train.py"],"metadata":{"id":"Jwb_jpszVEHL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677136244990,"user_tz":-540,"elapsed":11232,"user":{"displayName":"ë°•ì„±í™˜","userId":"16608640204304641951"}},"outputId":"15f28013-844c-434f-c41a-dda978d97bcb"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-23 07:10:34.954086: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-23 07:10:35.084619: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-02-23 07:10:35.865162: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-23 07:10:35.865256: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-23 07:10:35.865275: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","train.py:23: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"./\", config_name=\"config\")\n","/usr/local/lib/python3.8/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","Some weights of the model checkpoint at beomi/KcELECTRA-base-v2022 were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base-v2022 and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","data : /content/drive/MyDrive/MemeProject/data/train.json\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-df65470d7c475c64/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n","Downloading data files: 100% 1/1 [00:00<00:00, 3004.52it/s]\n","Extracting data files: 100% 1/1 [00:00<00:00,  1.87it/s]\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-df65470d7c475c64/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n","100% 1/1 [00:00<00:00, 587.68it/s]\n","test : DatasetDict({\n","    train: Dataset({\n","        features: ['content', 'label'],\n","        num_rows: 9150\n","    })\n","})\n"]}]},{"cell_type":"markdown","source":["# Predict"],"metadata":{"id":"PfcKvvMeB78X"}},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/MemeProject/src/pytorch/')"],"metadata":{"id":"4jT7p25KoLli"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python3 predict.py"],"metadata":{"id":"GBm7M5KyTEA6","executionInfo":{"status":"ok","timestamp":1675823540341,"user_tz":-540,"elapsed":29282,"user":{"displayName":"ë°•ì„±í™˜","userId":"16608640204304641951"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a13997c8-b985-4a47-82fb-8de477eb0b02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-08 02:31:55.354660: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","predict.py:11: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\"./\", config_name=\"config\")\n","/usr/local/lib/python3.8/dist-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","load tokenizer...\n","Downloading (â€¦)okenizer_config.json: 100% 288/288 [00:00<00:00, 43.4kB/s]\n","Downloading (â€¦)lve/main/config.json: 100% 504/504 [00:00<00:00, 83.0kB/s]\n","Downloading (â€¦)solve/main/vocab.txt: 100% 450k/450k [00:00<00:00, 3.10MB/s]\n","Downloading (â€¦)cial_tokens_map.json: 100% 124/124 [00:00<00:00, 53.2kB/s]\n","tokenizer loading done!\n","model loading done!\n","extension : .pickle\n","Loaded 181704 records from /content/drive/MyDrive/MemeProject/data/augmentation/origin_class120_ref.pickle\n","extension : .pickle\n","Loaded 120 records from /content/drive/MyDrive/MemeProject/data/under_label.pickle\n","--------------------------------------------------------\n","ðŸ¤— ëŒ€ê¸¸ì´ : ë§ ì¢€ ì°©í•˜ê²Œ í•˜ë¼ê³ \n","ðŸ¦ ëŒ€ì¶˜ì´ : ì„  ì„¸ê²Œ ë„˜ë„¤..! ì•„ì£¼ ì”¨~ê²Œ ë„˜ì–´~!\n"," \n","ðŸ¤— ëŒ€ê¸¸ì´ : ë” ë„“ì€ ê³³ì—ì„œ ì‚´ê³  ì‹¶ë‹¤\n","ðŸ¦ ëŒ€ì¶˜ì´ : ê·¸ëŸ° ê³³ì´... ì„ë§¤ë‚˜ ë¹„ì‹¸ê²Œìš”...? ì§€ê¸ˆê¹Œì§€ ì´ëŸ° ì˜¤í”¼ìŠ¤í…”ì€ ì—†ì—ˆë‹¤ ì´ê²ƒì€ ê¶ê¶ì¸ê°€ ì§‘ì¸ê°€...\n"," \n","ðŸ¤— ëŒ€ê¸¸ì´ : ë„ˆê°€ ë¹¨ëž˜ í•´ë†”\n","ðŸ¦ ëŒ€ì¶˜ì´ : ë„ˆ ë‚˜í•œí…Œ í™˜ìƒìžˆë„¤;; ì´ê±´ ë­ SF ìž¬ì§ˆ?\n"," \n","ðŸ¤— ëŒ€ê¸¸ì´ : ë„ˆ ë¦¬ì–¼ ë³„ë¡œ\n","ðŸ¦ ëŒ€ì¶˜ì´ : ì·¨í–ˆë‚˜ ë³´ë‹¤ ê·¸ê±° ë‚´ ì´ë¦„ ì•„ë‹Œë°,,, ì˜¤ëŠ˜ í•  ì¼ ëª©ë¡ : ìž‘ì‚´ë‚˜ê²Œ ìž ìˆ˜íƒ€ê¸°\n"," \n","ðŸ¤— ëŒ€ê¸¸ì´ : ìŠ¤ì¿¼íŠ¸ ì¸ìƒ ê¸°ë¡ ì°ì–´ì•¼ì§€\n","ðŸ¦ ëŒ€ì¶˜ì´ : ìš´ë™ ì‹œìž‘ ë°”ë¡œ ë‹¤ìŒ ë‚  ì˜ì§€ ë–¡ë½\n"," \n","ðŸ¤— ëŒ€ê¸¸ì´ : ë§ ì¢€ ì°©í•˜ê²Œ í•˜ë¼ê³ \n","ðŸ¦ ëŒ€ì¶˜ì´ : ë„ˆë¬´í•´ì˜¤... ë“œë¥´ë¥µ íƒ... ë„ˆë¬´í•´ì˜¤... ë“œë¥´ë¥µ íƒ... ë„ˆë¬´í•´ì˜¤... ë“œë¥´ë¥µ íƒ... ë‚˜ëŠ”ìš”, ì™„ì „ížˆ ë©˜ë¶•ëì–´ìš”...\n"," \n","ðŸ¤— ëŒ€ê¸¸ì´ : ë” ë„“ì€ ê³³ì—ì„œ ì‚´ê³  ì‹¶ë‹¤\n","ðŸ¦ ëŒ€ì¶˜ì´ : ë‚˜ë„ë‚˜ë„! ê¿ˆì€ ì—†ê³ ìš”~ ê·¸ëƒ¥ ë†€ê³  ì‹¶ìŠµë‹ˆë‹¤~~!\n"," \n","ðŸ¤— ëŒ€ê¸¸ì´ : ë¶€ìžë˜ê³  ì‹¶ë‹¤ ë¦¬ì–¼\n","ðŸ¦ ëŒ€ì¶˜ì´ : ë¡œë˜ ë‹¹ì²¨ ê³ ê³  ì–´ë•Œìš” ì°¸ ì‰½ì£ ?\n"," \n","--------------------------------------------------------\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"hK1W8H5AyYYl"},"execution_count":null,"outputs":[]}]}